{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3212303b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/xuenhui/anaconda3/envs/patch_base-py362/lib/python36.zip',\n",
       " '/home/xuenhui/anaconda3/envs/patch_base-py362/lib/python3.6',\n",
       " '/home/xuenhui/anaconda3/envs/patch_base-py362/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/home/xuenhui/anaconda3/envs/patch_base-py362/lib/python3.6/site-packages',\n",
       " '/home/xuenhui/anaconda3/envs/patch_base-py362/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/home/xuenhui/.ipython',\n",
       " '/home/xuenhui/anaconda3/envs/patch-py362/lib/python36.zip',\n",
       " '/home/xuenhui/anaconda3/envs/patch-py362/lib/python3.6',\n",
       " '/home/xuenhui/anaconda3/envs/patch-py362/lib/python3.6/lib-dynload',\n",
       " '/home/xuenhui/anaconda3/envs/patch-py362/lib/python3.6/site-packages']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看导包路径\n",
    "import sys \n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c41e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#添加导包路径\n",
    "sys.path.append('/home/xuenhui/anaconda3/envs/patch-py362/lib/python36.zip')\n",
    "sys.path.append('/home/xuenhui/anaconda3/envs/patch-py362/lib/python3.6')\n",
    "sys.path.append('/home/xuenhui/anaconda3/envs/patch-py362/lib/python3.6/lib-dynload')\n",
    "sys.path.append('/home/xuenhui/anaconda3/envs/patch-py362/lib/python3.6/site-packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f52cd2",
   "metadata": {},
   "source": [
    "Solution: The 340-dimensional feature vector was selected using the baseline scheme and combined with the 5 name features extracted from the test1 scheme to form a final 345-dimensional vector, which was modeled using XGB, and the results after grid search were fused with those of the baseline method (using fea340). The highest scoring test3 was obtained (0.5911, 0.6656)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a19e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.stats\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "def read_mat(mat_path):\n",
    "  mat = scipy.io.loadmat(mat_path)\n",
    "  mat = np.asarray(mat['feats_mat'], dtype=np.float)\n",
    "  mat[np.isnan(mat)] = 0\n",
    "  mat[np.isinf(mat)] = 0\n",
    "  return mat\n",
    "# load fea340\n",
    "train_fea = read_mat(os.path.join('feats/selected_340', 'DFGC-train_DFGC1st_withstd_feats340.mat'))\n",
    "test1_fea = read_mat(os.path.join('feats/selected_340', 'DFGC-test1_DFGC1st_withstd_feats340.mat'))\n",
    "test2_fea = read_mat(os.path.join('feats/selected_340', 'DFGC-test2_DFGC1st_withstd_feats340.mat'))\n",
    "test3_fea = read_mat(os.path.join('feats/selected_340', 'DFGC-test3_DFGC1st_withstd_feats340.mat'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f7ca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training set label\n",
    "import pandas as pd\n",
    "label_path = r'./data/label'\n",
    "df_train = pd.read_csv(os.path.join(label_path, 'train_set.csv'), skiprows=[])\n",
    "train_label = np.array(list(df_train['mos']), dtype=np.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64db88a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 340)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5046e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load name_fea\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv('data/label/train_set.csv')\n",
    "test1 = pd.read_csv('data/label/test_set1.txt', names=['file'])\n",
    "test2 = pd.read_csv('data/label/test_set2.txt', names=['file'])\n",
    "test3 = pd.read_csv('data/label/test_set3.txt', names=['file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45049886",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train.drop(['mos'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd2f3d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "features['file_name'] = features['file'].apply(lambda x: x.split(\"/\")[0])\n",
    "features['id1'] = features['file'].apply(lambda x: x.split(\"/\")[1].split(\"-\")[0])\n",
    "features['id2'] = features['file'].apply(lambda x: x.split(\"/\")[1].split(\"-\")[1])\n",
    "features['id3'] = features['file'].apply(lambda x: x.split(\"/\")[1].split(\"-\")[2])\n",
    "features['man'] = features['file'].apply(lambda x: x.split(\"/\")[1].split(\"-\")[-1].split(\".\")[0])\n",
    "\n",
    "test1_features = test1\n",
    "test1_features['file_name'] = test1_features['file'].apply(lambda x: x.split(\"/\")[0])\n",
    "test1_features['id1'] = test1_features['file'].apply(lambda x: x.split(\"/\")[1].split(\"-\")[0])\n",
    "test1_features['id2'] = test1_features['file'].apply(lambda x: x.split(\"/\")[1].split(\"-\")[1])\n",
    "test1_features['id3'] = test1_features['file'].apply(lambda x: x.split(\"/\")[1].split(\"-\")[2])\n",
    "test1_features['man'] = test1_features['file'].apply(lambda x: x.split(\"/\")[1].split(\"-\")[-1].split(\".\")[0])\n",
    "\n",
    "test2_features = test2\n",
    "test2_features['file_name'] = test2_features['file'].apply(lambda x: x.split(\"/\")[0])\n",
    "test2_features['id1'] = test2_features['file'].apply(lambda x: x.split(\"/\")[1].split(\"-\")[0])\n",
    "test2_features['id2'] = test2_features['file'].apply(lambda x: x.split(\"/\")[1].split(\"-\")[1])\n",
    "test2_features['id3'] = test2_features['file'].apply(lambda x: x.split(\"/\")[1].split(\"-\")[2])\n",
    "test2_features['man'] = test2_features['file'].apply(lambda x: x.split(\"/\")[1].split(\"-\")[-1].split(\".\")[0])\n",
    "\n",
    "test3_features = test3\n",
    "test3_features['file_name'] = test3_features['file'].apply(lambda x: x.split(\"/\")[0])\n",
    "test3_features['id1'] = test3_features['file'].apply(lambda x: x.split(\"/\")[1].split(\"-\")[0])\n",
    "test3_features['id2'] = test3_features['file'].apply(lambda x: x.split(\"/\")[1].split(\"-\")[1])\n",
    "test3_features['id3'] = test3_features['file'].apply(lambda x: x.split(\"/\")[1].split(\"-\")[2])\n",
    "test3_features['man'] = test3_features['file'].apply(lambda x: x.split(\"/\")[1].split(\"-\")[-1].split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17f670f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a tag before merging to facilitate splitting\n",
    "features['tag'] = 'train'\n",
    "test1_features['tag'] = 'test1'\n",
    "test2_features['tag'] = 'test2'\n",
    "test3_features['tag'] = 'test3'\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "# It is necessary to combine the training set and the test set, and then do LabelEncoder uniformly\n",
    "all_df = pd.concat([features, test1_features, test2_features, test3_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1755300",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = all_df.drop(['file'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28b8169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform LabelEncoder on id1\n",
    "all_df['id1'] = all_df['id1'].astype('str')\n",
    "all_df['id1'] = le.fit_transform(all_df['id1'])\n",
    "\n",
    "all_df['id2'] = all_df['id2'].astype('str')\n",
    "all_df['id2'] = le.fit_transform(all_df['id2'])\n",
    "\n",
    "all_df['id3'] = all_df['id3'].astype('str')\n",
    "all_df['id3'] = le.fit_transform(all_df['id3'])\n",
    "\n",
    "all_df['file_name'] = all_df['file_name'].astype('str')\n",
    "all_df['file_name'] = le.fit_transform(all_df['file_name'])\n",
    "\n",
    "all_df['man'] = all_df['man'].astype('str')\n",
    "all_df['man'] = le.fit_transform(all_df['man'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "175041f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the encoded features into train, test1, test2, test3\n",
    "features['file_name'] = all_df[all_df['tag']=='train']['file_name']\n",
    "features['id1'] = all_df[all_df['tag']=='train']['id1']\n",
    "features['id2'] = all_df[all_df['tag']=='train']['id2']\n",
    "features['id3'] = all_df[all_df['tag']=='train']['id3']\n",
    "features['man'] = all_df[all_df['tag']=='train']['man']\n",
    "features = features.drop(['tag'],axis = 1)\n",
    "features = features.drop(['file'],axis = 1)\n",
    "\n",
    "\n",
    "test1_features['file_name'] = all_df[all_df['tag']=='test1']['file_name']\n",
    "test1_features['id1'] = all_df[all_df['tag']=='test1']['id1']\n",
    "test1_features['id2'] = all_df[all_df['tag']=='test1']['id2']\n",
    "test1_features['id3'] = all_df[all_df['tag']=='test1']['id3']\n",
    "test1_features['man'] = all_df[all_df['tag']=='test1']['man']\n",
    "test1_features = test1_features.drop(['tag'],axis = 1)\n",
    "test1_features = test1_features.drop(['file'],axis = 1)\n",
    "\n",
    "\n",
    "test2_features['file_name'] = all_df[all_df['tag']=='test2']['file_name']\n",
    "test2_features['id1'] = all_df[all_df['tag']=='test2']['id1']\n",
    "test2_features['id2'] = all_df[all_df['tag']=='test2']['id2']\n",
    "test2_features['id3'] = all_df[all_df['tag']=='test2']['id3']\n",
    "test2_features['man'] = all_df[all_df['tag']=='test2']['man']\n",
    "test2_features = test2_features.drop(['tag'],axis = 1)\n",
    "test2_features = test2_features.drop(['file'],axis = 1)\n",
    "\n",
    "\n",
    "test3_features['file_name'] = all_df[all_df['tag']=='test3']['file_name']\n",
    "test3_features['id1'] = all_df[all_df['tag']=='test3']['id1']\n",
    "test3_features['id2'] = all_df[all_df['tag']=='test3']['id2']\n",
    "test3_features['id3'] = all_df[all_df['tag']=='test3']['id3']\n",
    "test3_features['man'] = all_df[all_df['tag']=='test3']['man']\n",
    "test3_features = test3_features.drop(['tag'],axis = 1)\n",
    "test3_features = test3_features.drop(['file'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d9dbb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 340)\n",
      "(700, 5)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# splicing of fea340 and name_fea\n",
    "\n",
    "#convert data type：pandas.core.frame.DataFrame -->  numpy.ndarray\n",
    "features = features.values\n",
    "print(train_fea.shape)\n",
    "print(features.shape)\n",
    "print(type(train_fea))\n",
    "print(type(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d4bce7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00405909, -2.01999879,  1.96036637, ...,  0.0287498 ,\n",
       "         0.01503708,  0.03093584],\n",
       "       [ 0.53068542, -0.5901233 ,  2.67612171, ...,  0.02590029,\n",
       "         0.02505589,  0.02585017],\n",
       "       [ 0.66390783, -1.39681458,  1.18705714, ...,  0.01451662,\n",
       "         0.01090694,  0.02874019],\n",
       "       ...,\n",
       "       [-0.43294653, -1.75199115,  0.04795574, ...,  0.05205392,\n",
       "         0.04071713,  0.05904517],\n",
       "       [-0.16586778, -1.45879996,  0.29791114, ...,  0.05937014,\n",
       "         0.02364715,  0.04718614],\n",
       "       [ 0.14763498, -1.10856962,  0.50533921, ...,  0.05936996,\n",
       "         0.02414202,  0.0443061 ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48cd1d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  7,  0],\n",
       "       [ 0,  0,  0,  7,  2],\n",
       "       [ 0,  0,  0,  7,  3],\n",
       "       ...,\n",
       "       [ 2, 19,  1, 12, 30],\n",
       "       [ 2, 19,  1, 12, 31],\n",
       "       [ 2, 19,  1, 12, 32]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b576a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fea = np.concatenate((train_fea,features),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3db6f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 345)\n"
     ]
    }
   ],
   "source": [
    "print(train_fea.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e69f5530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 345)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1_fea = np.concatenate((test1_fea,test1_features),axis=1)\n",
    "test1_fea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29759396",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_fea = np.concatenate((test2_fea,test2_features),axis=1)\n",
    "test3_fea = np.concatenate((test3_fea,test3_features),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83befb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_fea))\n",
    "\n",
    "print(type(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc35f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling with XGBRegressor\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_fea,train_label, test_size=0.3, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1364724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5930199207844162"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=1000, max_depth=5,\n",
    "         subsample=0.6, colsample_bytree=0.8, learning_rate=0.05, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afe08e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5204358328825381"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "pred = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0897e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_pred = model.predict(test1_fea)\n",
    "test2_pred = model.predict(test2_fea)\n",
    "test3_pred = model.predict(test3_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d7c4d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79f06ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在3折数据上的交叉验证\n",
      "均方根误差:\n",
      "0.5514872325056268\n",
      "拟合优度\n",
      "0.48346335085517167\n",
      "均方根误差:\n",
      "0.5450997686007977\n",
      "拟合优度\n",
      "0.5227430332509759\n",
      "均方根误差:\n",
      "0.5196535871886602\n",
      "拟合优度\n",
      "0.547531596647326\n",
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "0.547516598563219\n",
      "{'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 800}\n"
     ]
    }
   ],
   "source": [
    "# regression cross validation\n",
    "rng = np.random.RandomState(123)\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=rng)\n",
    "print(\"在3折数据上的交叉验证\")\n",
    "\n",
    "for train_index, test_index in kf.split(train_fea):\n",
    "    xgb_model = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "                                 n_estimators=300, \n",
    "                                 max_depth=6,\n",
    "                                 subsample=0.6,\n",
    "                                 colsample_bytree=0.8,learning_rate=0.1,random_state=0)\n",
    "    xgb_model.fit(train_fea[train_index],train_label[train_index])                             \n",
    "    predictions = xgb_model.predict(train_fea[test_index])\n",
    "    actuals = train_label[test_index]\n",
    "    print(\"均方根误差:\")\n",
    "    print(np.sqrt(mean_squared_error(actuals, predictions)))\n",
    "    print('拟合优度')\n",
    "    print(xgb_model.score(train_fea[test_index],train_label[test_index]))\n",
    "\n",
    "    \n",
    "    \n",
    "# Regression grid search for optimal hyperparameters\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "                         subsample=0.6, \n",
    "                         colsample_bytree=0.8, \n",
    "                         random_state=0,nthread=8)\n",
    "param_dict = {'max_depth': [5,6,4,7],\n",
    "              'n_estimators': [800,1000,1200],\n",
    "              'learning_rate':[0.05,0.1,0.2]}\n",
    "              \n",
    "clf = GridSearchCV(model, param_dict, cv=10, verbose=1 , scoring='r2')\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8e25385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "test3_pred = clf.predict(test3_fea)\n",
    "ttest3 = pd.read_csv(os.path.join(label_path, 'test_set3.txt'), names=['file'])\n",
    "\n",
    "test3_res = pd.DataFrame(ttest3['file'])\n",
    "test3_res['mos'] = test3_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02f617c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>mos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1/3-1-2-submit-73479.mp4</td>\n",
       "      <td>2.161089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1/3-2-5-submit-73479.mp4</td>\n",
       "      <td>2.470070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1/4-1-1-submit-73479.mp4</td>\n",
       "      <td>1.990804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1/4-2-2-submit-73479.mp4</td>\n",
       "      <td>2.032979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C1/8-1-1-submit-73479.mp4</td>\n",
       "      <td>1.520394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>C3/8-2-10-submit-00000.mp4</td>\n",
       "      <td>2.135617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>C3/8-2-10-submit-92147.mp4</td>\n",
       "      <td>2.059752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>C3/8-2-10-submit-92584.mp4</td>\n",
       "      <td>1.808838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>C3/8-2-10-submit-93014.mp4</td>\n",
       "      <td>2.206212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>C3/8-2-10-submit-93060.mp4</td>\n",
       "      <td>2.220459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           file       mos\n",
       "0     C1/3-1-2-submit-73479.mp4  2.161089\n",
       "1     C1/3-2-5-submit-73479.mp4  2.470070\n",
       "2     C1/4-1-1-submit-73479.mp4  1.990804\n",
       "3     C1/4-2-2-submit-73479.mp4  2.032979\n",
       "4     C1/8-1-1-submit-73479.mp4  1.520394\n",
       "..                          ...       ...\n",
       "115  C3/8-2-10-submit-00000.mp4  2.135617\n",
       "116  C3/8-2-10-submit-92147.mp4  2.059752\n",
       "117  C3/8-2-10-submit-92584.mp4  1.808838\n",
       "118  C3/8-2-10-submit-93014.mp4  2.206212\n",
       "119  C3/8-2-10-submit-93060.mp4  2.220459\n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read baseline: test3 results of fea340+svr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "path = r'./pred/baseline_feas340_cv10_grid'\n",
    "path_test3 = pd.read_csv(os.path.join(path, 'DFGC-test3_DFGC1st_withstd_feats340_pred.txt'), names=['file','mos'])\n",
    "path_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45f2f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average the two test3 and save the file\n",
    "test3_res['mos2'] = path_test3['mos']\n",
    "temp3 = test3_res[['mos', 'mos2']]\n",
    "test3_res[\"avg\"] = temp3.mean(axis=1)\n",
    "test3_res = test3_res.drop(['mos','mos2'],axis = 1)\n",
    "test3_res.to_csv(os.path.join(r'./pred/combine_test3/', 'Test3_preds.txt'), index=None, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (patch_base-py362)",
   "language": "python",
   "name": "patch_base-py362"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
